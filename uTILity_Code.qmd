---
title: "Code for the Processing and Integration of uTILity"
author: 
- name: Nick Borcherding
  email: ncborch@gmail.com
  affiliation: Washington University in St. Louis, School of Medicine, St. Louis, MO, USA
date: "`r format(Sys.Date(), '%B %d, %Y')`"
format:
  pdf:
    pdf-engine: xelatex
    keep-tex: true
    toc: true
    number-sections: true
    fig-cap-location: top
    geometry: margin=1in
    fontsize: 11pt
editor: visual
---

```{r}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE,
                      tidy = FALSE)
```

# Introduction

The original intent of assembling a data set of publicly-available tumor-infiltrating T cells (TILs) with paired TCR sequencing was to expand and improve the [scRepertoire](https://github.com/ncborcherding/scRepertoire) R package. However, after some discussion, we decided to release the data set for everyone, a complete summary of the sequencing runs and the sample information can be found in the meta data of the Seurat object.

The code below is the general purpose variant for the vast majority of samples - there are cohorts

## Citation

utility is not published nor has it gone through peer review. If utilizing the data, please cite the corresponding data sets. This can be found under **"Cohort"** in the meta data.

## Questions or Comments

Questions, comments, suggestions, please feel free to contact Nick Borcherding via this repository or [email](mailto:ncborch@gmail.com). **Also** if you are interested in dimensional reduction of TCR sequencing data, please get in touch as that is the intent of the assembled data and we would love to talk more!

# Loading Libraries

```{r}
# ---- Package loading ----
pkgs <- c(
  "Azimuth", "BiocParallel", "BPCells", "celldex",
  "cluster", "dplyr", "FNN", "future", "future.apply", 
  "ggplot2", "harmony", "Matrix", "mclust", "parallel", 
  "patchwork", "purrr", "RColorBrewer", "reticulate", 
  "scDblFinder", "scRepertoire", "scran", "Seurat", 
  "SeuratData", "SingleCellExperiment", "SingleR", "viridis")

invisible(lapply(pkgs, function(pkg) {
  suppressPackageStartupMessages(library(pkg, character.only = TRUE))
}))

# ---- Custom functions ----
source("./R/utils.R")
source("./R/checkAndUpdateGenes.R")
```

# Loading and Processing the Data

## Load, filter and combine Data

```{r eval=FALSE}
dir.create("./qc")

file_list <- list.files("./data/SequencingRuns")

###########################
#Load Annotation Reference
###########################
HPCA <- HumanPrimaryCellAtlasData()
Monaco <- MonacoImmuneData()

options(Seurat.object.assay.version = "v5")

for (i in seq_along(file_list)){
    tmp <-  Read10X(paste0("./data/SequencingRuns/", file_list[i]))
    if(inherits(tmp, "list")) {
      tmp <- tmp[[1]]
     # rownames(tmp) <- stringr::str_split(rownames(tmp), "_", simplify = TRUE)[,2]
      #tmp <- tmp[rownames(tmp) != "",]
    }
   
    
    tmp <- CreateAssayObject(counts = tmp)
    SeuratObj <-  CreateSeuratObject(counts = tmp, 
                                     assay = "RNA",
                               project = file_list[i])
    SeuratObj$nCount_RNA <- colSums(SeuratObj@assays$RNA@counts)
    SeuratObj$nFeature_RNA <- colSums(SeuratObj@assays$RNA@counts != 0)
    
    SeuratObj <-  subset(SeuratObj, subset = nFeature_RNA > 100) #filter out low count/feature cells
    SeuratObj  <- RenameCells(object = SeuratObj , new.names = paste0(file_list[i], "_", rownames(SeuratObj[[]])))
    
    SeuratObj[["mito.genes"]] <- PercentageFeatureSet(SeuratObj, pattern = "^MT-")
    SeuratObj[["ribo.genes"]] <- PercentageFeatureSet(SeuratObj, pattern = "^RPS|RPL-")
    
    VlnPlot(object = SeuratObj, 
            features = c("nCount_RNA", "nFeature_RNA", "mito.genes", "ribo.genes"), 
            pt.size = 0) + 
      theme(legend.position = "none") + 
      plot_layout(ncol =2)
    ggsave(paste0("./qc/", file_list[i], ".pdf"), height = 8, width=8)
    
    
    ###########################
    #Here is the filtering step
    ############################
    standev <- sd(log(SeuratObj$nFeature_RNA))*2.5 #cutting off above standard deviation of 2.5
    mean <- mean(log(SeuratObj$nFeature_RNA))
    cut <- round(exp(standev+mean))
    SeuratObj <- subset(SeuratObj, subset = mito.genes < 10 & nFeature_RNA < cut)
    
    ###########################################
    #Estimate Doublets for Each Sequencing Run
    ############################################
    sce <- as.SingleCellExperiment(SeuratObj)
    sce <- scDblFinder(sce)
    doublets <- data.frame(db.class = sce$scDblFinder.class, db.score = sce$scDblFinder.score)
    rownames(doublets) <- rownames(sce@colData)
    SeuratObj <- AddMetaData(SeuratObj, doublets)

    
    ###########################################
    #Seurat Azimuth Annotation
    ############################################
    SeuratObj <- NormalizeData(SeuratObj, verbose = FALSE)
    SeuratObj <- ScaleData(SeuratObj, verbose = FALSE)
    VariableFeatures(SeuratObj) <- getTopHVGs(as.SingleCellExperiment(SeuratObj), 
                                        n=2000)
    SeuratObj <- RunPCA(SeuratObj, verbose = FALSE)
    SeuratObj<- RunUMAP(SeuratObj, dims = 1:30, verbose = FALSE)
    SeuratObj <- FindNeighbors(object = SeuratObj, 
                         features = VariableFeatures(SeuratObj), 
                         verbose = FALSE)
   
   SeuratObj <- RunAzimuth(SeuratObj, 
                      reference = "pbmcref",
                      verbose = FALSE)
      
    #############################################
    #Singler Annotation of Cell Types
    #############################################
      
    com.res1 <- SingleR(sce, ref=HPCA, labels=HPCA$label.fine, assay.type.test=1)
  
    df <- data.frame("labels" = com.res1$labels, "pruned.labels" = com.res1$pruned.labels)
    rownames(df) <- rownames(com.res1)
    colnames(df) <- paste0("HPCA.", colnames(df))
    SeuratObj <- AddMetaData(SeuratObj,  df)
  
    
    com.res2 <- SingleR(sce, ref=Monaco, labels=Monaco$label.fine, assay.type.test=1)
    df <- data.frame("labels" = com.res2$labels, "pruned.labels" = com.res2$pruned.labels)
    rownames(df) <- rownames(com.res1)
    colnames(df) <- paste0("Monaco.", colnames(df))
    SeuratObj <- AddMetaData(SeuratObj,  df)
    rm(df)
    rm(sce)
      
    ######################################
    #Adding TCR clonotypes
    ######################################
    
    TCR.file <- list.files(paste0("./data/SequencingRuns/", file_list[i]), pattern = "annotations")[1]
    if(is.na(TCR.file)) {
      SeuratObj$CTaa <- NA
      SeuratObj$CTnt <- NA
      SeuratObj$CTgene <- NA
      SeuratObj$CTstrict <- NA
      SeuratObj$clonalProportion <- NA
      SeuratObj$clonalFrequency <- NA
      SeuratObj$cloneSize <- NA
    } else {
      TCR.file <- read.csv(paste0("./data/SequencingRuns/", file_list[i], "/", TCR.file))
      combinedObject <- combineTCR(TCR.file, 
                                   samples = file_list[i], 
                                   filterMulti = TRUE)
      SeuratObj <- combineExpression(combinedObject, 
                               SeuratObj, 
                               cloneCall = "aa")
    }
    
    SeuratObj <- DietSeurat(SeuratObj)
    SeuratObj[["prediction.score.celltype.l1"]] <- NULL
    SeuratObj[["prediction.score.celltype.l2"]] <- NULL
    SeuratObj[["prediction.score.celltype.l3"]] <- NULL
    SeuratObj[["query_ref.nn"]] <- NULL
    SeuratObj@assays$RNA$scale.data <- NULL
    
    #################################
    #Saving Preliminary Seurat Object
    #################################
    saveRDS(SeuratObj, paste0("./data/processedData/seuratObjects/", file_list[i], ".rds"))
    rm(SeuratObj)
    rm(tmp)
    gc()
}
```

## Unifying Gene Symbol

As the data itself is combining processed and raw data from various versions of Cell Ranger - there are a number of gene nomenclature issues between cohorts. Here we will update the symbols using HGNC current standard, sum any duplicates and make new objects to save.

```{r eval = FALSE}
files <- list.files("./data/processedData/seuratObjects/")
names <- stringr::str_remove_all(files, ".rds")

for(i in seq_along(files)) {
    print(paste("Processing sample ",  names[i], " - ", i, " of ", length(names)))
    obj <- readRDS(paste0("./data/processedData/seuratObjects/", files[i]))
    obj$orig.ident <- names[i]
    meta <- obj[[]]
    
    updated.features <- checkAndUpdateGenes(rownames(obj), gene.symbols = gene.symbols)
    new.features <- updated.features[[1]]
    
    data <- obj@assays$RNA$count
  
  # Sum the rows based on new.features
  summed_data <- do.call(rbind,
      lapply(1:ncol(data), function(j) tapply(data[, j], new.features, sum, default = 0))
  )
  
  unique_features <- unique(new.features)
  dups <- new.features[duplicated(new.features) | duplicated(new.features, fromLast = TRUE)]
  
  # Create an empty matrix to hold the summed rows
  summed_matrix <- Matrix(0, nrow = length(unique_features), ncol = ncol(data), sparse = TRUE)
  rownames(summed_matrix) <- unique_features
  colnames(summed_matrix) <- colnames(data)
  
  
  unique_features <- unique(new.features)
  dups <- new.features[duplicated(new.features) | duplicated(new.features, fromLast = TRUE)]
  
  # Set up parallel computing
  no_cores <- detectCores() - 1  # Leave one core free for system processes
  cl <- makeCluster(no_cores)
  clusterExport(cl, list("data", "new.features", "dups", "unique_features", "colSums"))
  clusterEvalQ(cl, library(Matrix))  # Load Matrix package on each worker
  
  # Define function to process each feature
  process_feature <- function(feature) {
    rows_to_sum <- which(new.features == feature)
    if (feature %in% dups) {
      return(list(feature = feature, sum = colSums(data[rows_to_sum, , drop = FALSE])))
    } else {
      return(list(feature = feature, sum = data[rows_to_sum, , drop = FALSE]))
    }
  }
  
  # Use parallel processing
  results <- parLapply(cl, unique_features, process_feature)
  
  # Stop the cluster
  stopCluster(cl)
  
  for (result in results) {
    summed_matrix[result$feature, ] <- result$sum
  }
  
  new.obj <- CreateSeuratObject(counts = summed_matrix,
                                meta.data = meta)
  saveRDS(new.obj, paste0("./data/processedData/seuratObjects/", files[i]))
  rm(summed_matrix, results, obj, new.obj, data)
  gc()
}
```

# Integrating All Cells with BPCells and Harmony

Now we can take all the Seurat Objects and integrate them. The following code has been optimized for memory efficiency and scalability. It uses `BPCells` to store the count matrices on disk, avoiding the need to load the entire dataset into RAM. It then uses `harmony` for integration. The raw count matrices are first filtered and subset to a common feature space before being converted to the `BPCells` format.

```{r}
# This chunk uses BPCells to store data on-disk and Harmony for integration.

# 1. Setup BPCells directory
# Create a directory to store the on-disk BPCells matrices
bp_dir <- "./data/processedData/bpcells_matrices/"
if (!dir.exists(bp_dir)) {
  dir.create(bp_dir, recursive = TRUE)
}

# 2. Load feature space and file list
files <- list.files("./data/processedData/seuratObjects/")
names <- stringr::str_remove_all(files, ".rds")

# 3. Process objects one-by-one and convert to BPCells format
# This loop reads each Seurat object, applies initial filtering,
# and then writes the count matrix to an on-disk BPCells matrix. 
# This avoids loading all data into RAM at once.
for (x in seq_along(names)) {
  sample_name <- names[x]
  bp_path <- file.path(bp_dir, sample_name)
  meta_path <- file.path(bp_dir, paste0(sample_name, "_meta.rds"))
  features_path <- file.path(bp_path, "features.rds")
  barcodes_path <- file.path(bp_path, "barcodes.rds")

  if (dir.exists(bp_path) && file.exists(meta_path) && file.exists(features_path)) {
    message("Skipping already processed sample: ", sample_name)
    next()
  }

  obj <- readRDS(paste0("./data/processedData/seuratObjects/", files[x]))

  # Filtering
  if ("predicted.celltype.l1" %in% colnames(obj[[]])) {
    if (any(grepl("CD4 T|CD8 T|other T|NK", obj$predicted.celltype.l1))) {
      obj <- subset(obj, predicted.celltype.l1 %in% c("CD4 T", "CD8 T", "other T", "NK"))
    } else next()
  }
  if ("CTaa" %in% colnames(obj[[]])) {
    cells <- which(!is.na(obj[[]][, "CTaa"]))
    if (length(cells) == 0) next()
    obj <- subset(obj, cells = colnames(obj)[cells])
  }
  if ("db.class" %in% colnames(obj[[]])) {
    if (ncol(obj) == 0) next()
    obj <- subset(obj, db.class == "singlet")
  }
  if (ncol(obj) <= 1) next()

  obj$orig.ident <- sample_name

  # Write BPCells counts
  BPCells::write_matrix_dir(mat = obj@assays$RNA@layers$counts, dir = bp_path)

  # Save feature names
  saveRDS(rownames(obj), file = features_path)
  
  # Save feature names
  saveRDS(colnames(obj), file = barcodes_path)

  # Save metadata
  saveRDS(obj[[]], file = meta_path)

  rm(obj)
  gc()
}

# 4. Build the list of Seurat objects from disk
processed_names <- list.dirs(bp_dir, full.names = FALSE, recursive = FALSE)

object.list <- lapply(processed_names, function(p_name) {
  bp_path <- file.path(bp_dir, p_name)
  meta_path <- file.path(bp_dir, paste0(p_name, "_meta.rds"))
  features_path <- file.path(bp_path, "features.rds")
  barcodes_path <- file.path(bp_path, "barcodes.rds")

  counts_bp <- BPCells::open_matrix_dir(bp_path)
  rownames(counts_bp) <- readRDS(features_path)
  colnames(counts_bp) <- readRDS(barcodes_path)

  Seurat::CreateSeuratObject(
    counts = counts_bp,
    meta.data = readRDS(meta_path)
  )
})
names(object.list) <- processed_names


# 5. Identify features to integrate
per_sample_stats <- lapply(object.list, function(obj) {
  counts_bp <- obj@assays$RNA@layers$counts
  if (is.null(counts_bp)) counts_bp <- obj@assays$RNA@counts

  lib_sizes <- as.numeric(BPCells::colSums(counts_bp))
  lib_sizes[lib_sizes == 0] <- 1
  scale_factor <- median(lib_sizes)

  # Normalize (still on disk)
  norm_bp <- t(t(counts_bp) / lib_sizes) * scale_factor

  # Materialize to sparse matrix before log1p
  norm_mat <- as(norm_bp, "dgCMatrix")
  logcounts <- log1p(norm_mat)

  sce <- SingleCellExperiment(assays = list(logcounts = logcounts))
  diff <- scran::modelGeneVar(sce, assay.type = "logcounts")
  diff@rownames <- rownames(obj)
  return(diff)
})

# Harmonize features across samples
common_genes <- Reduce(intersect, lapply(per_sample_stats, rownames))
per_sample_stats <- lapply(per_sample_stats, function(stat) {
  stat[common_genes, , drop = FALSE]
})

# Combine variance stats and pick HVGs
combined_stats <- scran::combineVar(per_sample_stats)
top_hvg <- scran::getTopHVGs(combined_stats, n = 2035)

#Removing VDJ/Ribosomal/Mitochondrial Genes
variable.features <- scRepertoire::quietVDJgenes(top_hvg)
variable.features <- variable.features[!grepl('^RP[SL][[:digit:]]|^RPLP[[:digit:]]|^RPSA|^MT-', 
                                              variable.features)]

# Forming a Single Seurat Object
SeuratObj <- merge(object.list[[1]], object.list[-1])
rm(object.list)
gc()

SeuratObj <- SeuratObj %>%
              NormalizeData(verbose = FALSE) %>%
              ScaleData(features = variable.features,
                        verbose = FALSE) %>%
              RunPCA(verbose = FALSE, 
                     features = variable.features)

# Add tissue metadata
SeuratObj$tissue <- stringr::str_split(SeuratObj$orig.ident, 
                                       "[.]", 
                                        simplify = TRUE)[,2]

SeuratObj <- RunHarmony(SeuratObj,
                group.by.vars = c("tissue","orig.ident"),
                theta = c(tissue = 0.5, orig.ident = 8),
                lambda = 2,
                kmeans_init_nclust = 100,     # try 100–200
                kmeans_init_nstart = 10)

# 7. Dimensional Reduction
# We can proceed with downstream analysis like PCA and UMAP on the integrated data.
SeuratObj <- RunUMAP(SeuratObj,
                     reduction = "harmony",
                     dims = 1:30,
                     reduction.name = "umap.harmony")

saveRDS(SeuratObj, "./data/integratedSeuratObject.rds")
```

## Visualizing Integration and Dimensional Reduction

```{r}
SeuratObj <- readRDS("./data/integratedSeuratObject.rds")

p1 <- DimPlot(SeuratObj,
              reduction = "umap.harmony",
              group.by = "orig.ident") + 
  UtilityTheme(grid_lines = "No") + 
  guides(color = "none") + 
  xlab("UMAP1") + 
  ylab("UMAP2") + 
  scale_color_viridis(option = "H", discrete = TRUE) + 
  theme(plot.title = element_blank())

# Second DimPlot
p2 <- DimPlot(SeuratObj,
              reduction = "umap.harmony",
              group.by = "tissue") +
  UtilityTheme(grid_lines = "No") + 
  xlab("UMAP1") + 
  ylab("UMAP2") + 
  scale_color_viridis(option = "H", discrete = TRUE) + 
  theme(plot.title = element_blank())

p1 + p2 

# Feature plots of general Tcell Markers
fp <- FeaturePlot(SeuratObj, 
                  features = c("CD4", "CD8A", "FOXP3", 
                               "CCR7", "SELL", "IL7R", 
                               "IFNG","PDCD1", "CTLA4"), 
                  reduction = "umap.harmony", 
                  combine = FALSE)

fp <- lapply(fp, function(x) {
          x <- x + 
              UtilityTheme(grid_lines = "No") + 
              guides(color = "none") + 
              scale_color_viridis() + 
              theme(axis.title = element_blank(), 
                    axis.text = element_blank(), 
                    axis.ticks = element_blank())
})

wrap_plots(fp)
```

# Leiden Clustering and Evaluation

This section performs cell clustering using the Leiden algorithm, which is a fast and high-quality community detection algorithm. To determine the optimal clustering granularity, we systematically test a range of resolution parameters. The best resolution is selected by finding the one that maximizes the average silhouette width, a measure of cluster cohesion and separation.

```{r}
# ---- Parameters ----
#resolutions          <- seq(0.2, 2.0, by = 0.2)
resolution           <- seq(0.2, 0.6, by = 0.2)
B_bootstrap          <- 30L           # number of bootstraps 
n_graph_cells        <- 30000L        # cells per bootstrap for building 
n_sil_cells          <- 4000L         # cells per bootstrap for silhouette
random_seed          <- 42L
reduction_for_dist   <- "harmony"     # used for kNN + silhouette
reduction_for_plot   <- "umap.harmony"
dims_use             <- 1:30
k_param              <- 20            
tiny_cluster_n       <- 50L
min_overlap_for_ari  <- 800L          # only compute ARI for bootstrap 
nn_method            <- "annoy"       # memory-friendly approx kNN 
assay_for_clust      <- DefaultAssay(SeuratObj)

plan(sequential)
set.seed(random_seed)

all_cells <- colnames(SeuratObj)
emb_all   <- SeuratObj@reductions[[reduction_for_dist]]@cell.embeddings[, dims_use, drop = FALSE]

# ---- Main sweep with bootstrapping on subsets ----
results_list <- list()

for (res in resolutions) {
  message("Testing resolution: ", res)

  # Store per-bootstrap outputs
  boot_sil   <- numeric(B_bootstrap)
  boot_sizes <- vector("list", B_bootstrap)
  boot_ids   <- vector("list", B_bootstrap)   # named vectors of clusters for ARI

  for (bi in seq_len(B_bootstrap)) {
    set.seed(random_seed + bi)

    # 1) sample cells for this bootstrap (graph + clustering)
    cells_graph <- .sample_cells(n_graph_cells, all_cells)

    # 2) run neighbor graph & Leiden on the subset
    res_subset <- run_leiden_on_subset(SeuratObj, cells_graph, res)
    ids_sub    <- res_subset$ids
    boot_ids[[bi]] <- ids_sub

    # 3) QC on this bootstrap
    tab_b <- table(ids_sub)
    boot_sizes[[bi]] <- tab_b

    # 4) silhouette on a sub-subset (<= n_sil_cells) from this subset
    emb_sub <- Embeddings(res_subset$object, reduction = reduction_for_dist)[, dims_use, drop = FALSE]
    cells_sil <- .sample_cells(min(n_sil_cells, length(ids_sub)), names(ids_sub))
    sil_bi <- .silhouette_mean(labels = ids_sub, emb = emb_sub, max_n = n_sil_cells)
    boot_sil[bi] <- sil_bi
  }

  # Summaries (silhouette)
  sil_mu  <- mean(boot_sil, na.rm = TRUE)
  sil_sd  <- stats::sd(boot_sil, na.rm = TRUE)
  n_eff   <- sum(is.finite(boot_sil))
  sil_se  <- sil_sd / sqrt(max(1L, n_eff))
  ci95_lo <- sil_mu - 1.96 * sil_se
  ci95_hi <- sil_mu + 1.96 * sil_se

  # Summaries (cluster sizes averaged across bootstraps)
  avg_n_clusters <- mean(vapply(boot_sizes, length, 1L))
  avg_min_size   <- mean(vapply(boot_sizes, function(x) min(x), 1L))
  avg_pct_tiny   <- mean(vapply(boot_sizes, function(x) 100 * sum(x < tiny_cluster_n) / length(x), 1.0))

  # ---- Stability metric 2: ARI across bootstrap pairs on overlapping cells ----
  # Compute ARI on pairs that share enough sampled cells
  pair_ids <- combn(seq_len(B_bootstrap), 2, simplify = FALSE)
  ari_vals <- numeric(length(pair_ids))
  keep     <- logical(length(pair_ids))
  for (pi in seq_along(pair_ids)) {
    i <- pair_ids[[pi]][1]
    j <- pair_ids[[pi]][2]
    ids_i <- boot_ids[[i]]
    ids_j <- boot_ids[[j]]
    common <- intersect(names(ids_i), names(ids_j))
    if (length(common) >= min_overlap_for_ari) {
      ari_vals[pi] <- mclust::adjustedRandIndex(
        as.integer(factor(ids_i[common])),
        as.integer(factor(ids_j[common]))
      )
      keep[pi] <- TRUE
    } else {
      ari_vals[pi] <- NA_real_
    }
  }
  ari_use <- ari_vals[keep]
  ari_mu  <- if (length(ari_use)) mean(ari_use) else NA_real_
  ari_sd  <- if (length(ari_use)) stats::sd(ari_use) else NA_real_
  ari_se  <- if (length(ari_use)) ari_sd / sqrt(length(ari_use)) else NA_real_
  ari_lo  <- if (length(ari_use)) ari_mu - 1.96 * ari_se else NA_real_
  ari_hi  <- if (length(ari_use)) ari_mu + 1.96 * ari_se else NA_real_

  # Save
  results_list[[as.character(res)]] <- list(
    resolution = res,
    sil_boot   = boot_sil,
    sil_mean   = sil_mu,
    sil_sd     = sil_sd,
    sil_se     = sil_se,
    sil_ci95_low = ci95_lo,
    sil_ci95_hi  = ci95_hi,
    # stability metric 2
    ari_pairs  = ari_use,
    ari_mean   = ari_mu,
    ari_sd     = ari_sd,
    ari_se     = ari_se,
    ari_ci95_low = ari_lo,
    ari_ci95_hi  = ari_hi,
    # QC stats averaged across bootstraps
    avg_n_clusters   = avg_n_clusters,
    avg_min_size     = as.integer(avg_min_size),
    avg_pct_tiny     = avg_pct_tiny
  )
}

# ---- Tidy results ----
df_summary <- do.call(
  rbind,
  lapply(results_list, function(x) {
    data.frame(
      resolution       = x$resolution,
      avg_n_clusters   = x$avg_n_clusters,
      avg_min_size     = x$avg_min_size,
      avg_pct_tiny     = x$avg_pct_tiny,
      sil_mean         = x$sil_mean,
      sil_sd           = x$sil_sd,
      sil_se           = x$sil_se,
      sil_ci95_low     = x$sil_ci95_low,
      sil_ci95_hi      = x$sil_ci95_hi,
      ari_mean         = x$ari_mean,
      ari_sd           = x$ari_sd,
      ari_se           = x$ari_se,
      ari_ci95_low     = x$ari_ci95_low,
      ari_ci95_hi      = x$ari_ci95_hi,
      stringsAsFactors = FALSE
    )
  })
)
df_summary <- df_summary[order(df_summary$resolution), ]

df_boot_sil <- do.call(
  rbind,
  lapply(results_list, function(x) {
    data.frame(
      resolution = x$resolution,
      sil_boot   = x$sil_boot,
      stringsAsFactors = FALSE
    )
  })
)
df_boot_sil$resolution <- as.numeric(df_boot_sil$resolution)
df_boot_sil <- df_boot_sil[order(df_boot_sil$resolution), ]

df_boot_ari <- do.call(
  rbind,
  lapply(results_list, function(x) {
    if (length(x$ari_pairs)) {
      data.frame(resolution = x$resolution, ari_pair = x$ari_pairs)
    } else {
      NULL
    }
  })
)

# ---- Pick optimal resolution
# Primary: max silhouette; 
# tie-breaker: higher ARI; then fewer clusters
best_sil <- max(df_summary$sil_mean, na.rm = TRUE)
cand     <- which(df_summary$sil_mean >= (best_sil - 1e-12))
if (length(cand) > 1) {
  ari_sub <- df_summary$ari_mean[cand]
  if (all(is.na(ari_sub))) {
    cand <- cand[which.min(df_summary$avg_n_clusters[cand])]
  } else {
    best_ari <- max(ari_sub, na.rm = TRUE)
    cand2    <- cand[which(ari_sub >= (best_ari - 1e-12))]
    if (length(cand2) > 1) {
      cand <- cand2[which.min(df_summary$avg_n_clusters[cand2])]
    } else {
      cand <- cand2
    }
  }
}
optimal_resolution <- df_summary$resolution[cand]
```

## Visualizaton of Cluster Stability

```{r}
p1 <- ggplot(df_summary, aes(x = resolution, y = sil_mean)) +
  geom_ribbon(aes(ymin = sil_ci95_low, ymax = sil_ci95_hi), alpha = 0.15) +
  geom_line(size = 0.9) + geom_point(size = 2) +
  geom_vline(xintercept = optimal_resolution, linetype = 2) +
  labs(title = "Leiden resolution optimization (bootstrapped silhouette)",
       x = "Resolution", y = "Mean silhouette (±95% CI)") +
  theme_bw(base_size = 12) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

p2 <- ggplot(df_boot_sil, aes(x = factor(resolution), y = sil_boot, group = factor(resolution))) +
  geom_violin(trim = TRUE, width = 0.9) +
  geom_jitter(width = 0.08, alpha = 0.3, size = 0.6) +
  geom_hline(yintercept = 0, linetype = 3) +
  labs(title = paste0("Bootstrap silhouettes (B = ", B_bootstrap, ")"),
       x = "Resolution", y = "Silhouette width") +
  theme_bw(base_size = 12) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

p3 <- ggplot(df_summary, aes(x = resolution, y = avg_n_clusters)) +
  geom_line(size = 0.9) + geom_point(size = 2) +
  geom_vline(xintercept = optimal_resolution, linetype = 2) +
  labs(title = "Model complexity", x = "Resolution", y = "Avg # clusters") +
  theme_bw(base_size = 12) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

p3b <- ggplot(df_summary, aes(x = resolution, y = avg_pct_tiny)) +
  geom_line(size = 0.9) + geom_point(size = 2) +
  geom_vline(xintercept = optimal_resolution, linetype = 2) +
  labs(title = paste0("Tiny clusters (<", tiny_cluster_n, " cells)"),
       x = "Resolution", y = "% tiny clusters (avg)") +
  theme_bw(base_size = 12) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

p5 <- ggplot(df_summary, aes(x = resolution, y = ari_mean)) +
  geom_ribbon(aes(ymin = ari_ci95_low, ymax = ari_ci95_hi), alpha = 0.15) +
  geom_line(size = 0.9) + geom_point(size = 2) +
  geom_vline(xintercept = optimal_resolution, linetype = 2) +
  labs(title = "Cluster stability (pairwise ARI across bootstraps)",
       x = "Resolution", y = "Mean ARI (±95% CI)") +
  theme_bw(base_size = 12) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

( (p1 / p2) | (p3 / p3b) ) + patchwork::plot_layout(guides = "collect")
p5
```

# Assign final clusters to all cells

We take the best bootstrap at the optimal resolution, compute centroids in the embedding, and classify all cells by nearest centroid.

```{r}
best_res_key <- as.character(optimal_resolution)
sil_vec <- results_list[[best_res_key]]$sil_boot

best_bi <- which.max(sil_vec)

# Re-run that specific bootstrap to get its clustering & centroids
set.seed(random_seed + best_bi)
cells_graph <- .sample_cells(n_graph_cells, all_cells)
best_sub    <- run_leiden_on_subset(SeuratObj, cells_graph, optimal_resolution)$object
ids_best    <- Idents(best_sub) # factor with names = cells_graph

# Centroids in embedding space
emb_best <- Embeddings(best_sub, reduction = reduction_for_dist)[, dims_use, drop = FALSE]
centroid_mat <- do.call(rbind, lapply(split(emb_best, ids_best), function(m) {
  m <- as.matrix(m)
  colMeans(matrix(m, ncol = ncol(emb_best)))
}))
centroid_labels <- rownames(centroid_mat)

# Assign all cells by nearest centroid (fast)
assign_by_centroid <- function(emb_all, centroids, chunk = 100000L) {
  n <- nrow(emb_all)
  idx <- vector("integer", length = n)
  rn  <- rownames(emb_all)
  for (start in seq(1, n, by = chunk)) {
    end <- min(n, start + chunk - 1L)
    q <- emb_all[start:end, , drop = FALSE]
    nn <- FNN::knnx.index(data = centroids, query = q, k = 1)
    idx[start:end] <- nn[, 1]
  }
  factor(centroid_labels[idx], levels = centroid_labels, labels = centroid_labels, ordered = FALSE)
}

final_labels <- assign_by_centroid(emb_all = emb_all, centroids = centroid_mat)
names(final_labels) <- rownames(emb_all)

SeuratObj$leiden_clusters <- final_labels

# UMAP colored by final labels
p4 <- DimPlot(
  SeuratObj,
  reduction = reduction_for_plot,
  group.by  = "leiden_clusters",
  label = TRUE, repel = TRUE
) + theme(plot.title = element_blank())

p4

# Save
saveRDS(SeuratObj, "./data/integratedSeuratObject.rds")
```

# T Cell Type Assignments

```{r}
# TODO Working on integration
```

# Conclusion

```{r}
sessionInfo()
```
