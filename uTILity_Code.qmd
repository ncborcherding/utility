---
title: "Benchmarking Integration Methods for the uTILity Atlas"
author: 
- name: "Pipeline generated by Jules"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
format:
  html:
    toc: true
    number-sections: true
    fig-cap-location: top
    embed-resources: true
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE,
                      tidy = FALSE)
```

# Introduction

This document outlines a reproducible benchmarking pipeline designed to evaluate and compare multiple single-cell integration methods on the uTILity atlas. The original analysis has been refactored into a modular, configurable pipeline that allows for robust comparison of methods based on quantitative metrics.

The pipeline performs the following key steps:

1.  **Data Loading**: Loads pre-processed Seurat objects.
2.  **Subsetting**: Subsets the data to a manageable size using stratified sampling.
3.  **Preprocessing**: Standardizes variable feature selection across all methods.
4.  **Integration**: Runs five different integration methods: Seurat CCA, Harmony, fastMNN, scVI, and scANVI.
5.  **Analysis & Metrics**: For each method, it computes a UMAP, clusters the cells, and calculates a suite of metrics for batch correction and cell type label conservation.
6.  **Ranking & Visualization**: Aggregates all metrics, normalizes them, and produces a ranked "league table" of methods, along with various summary plots.

The entire pipeline is controlled by a central `config.yaml` file and can be executed with a single script.

# Running the Pipeline

The following code chunk executes the entire benchmarking pipeline by sourcing the main `run_pipeline.R` script. The `eval=FALSE` option is set so it does not run automatically when this document is rendered; it should be run interactively or via a script. The results presented below are loaded from the output of a previous run.

```{r run-pipeline, eval=FALSE}
# This script runs the entire end-to-end pipeline.
# It will load data, subset, preprocess, integrate, and generate all metrics/plots.
# This may take a significant amount of time to run.

source("run_pipeline.R")

# The pipeline can also be run from the command line:
# Rscript run_pipeline.R --config config.yaml
```

# Results

The following sections display the primary outputs generated by the pipeline.

## Method Ranking

The core output is a "league table" that ranks each integration method based on a weighted global score, combining performance on batch correction and label conservation.

```{r show-ranking-table, echo=FALSE}
# Load and display the summary table image created by the pipeline
ranking_table_path <- "./figs/05_summary_table.png"
if (file.exists(ranking_table_path)) {
  knitr::include_graphics(ranking_table_path)
} else {
  "Summary table image not found. Please run the pipeline first."
}
```

## Normalized Metrics Heatmap

To visualize the trade-offs of each method, we can view a heatmap of the normalized scores (0-1 scale, higher is better) across all metrics.

```{r show-heatmap, echo=FALSE}
heatmap_path <- "./figs/02_heatmap_normalized_metrics.png"
if (file.exists(heatmap_path)) {
  knitr::include_graphics(heatmap_path)
} else {
  "Heatmap image not found. Please run the pipeline first."
}
```

## UMAP Comparative Plots

UMAP visualizations provide a qualitative assessment of how well each method mixes batches while preserving biological structure. Below are the UMAPs for each method, colored by batch (`orig.ident`) and cell type (`predicted.celltype.l2`).

```{r show-umaps, echo=FALSE}
# Dynamically find and display all UMAP plots
figure_dir <- "./figs/"
umap_files <- list.files(figure_dir, pattern = "^04_umap_.*\\.png$", full.names = TRUE)

if (length(umap_files) > 0) {
  knitr::include_graphics(umap_files)
} else {
  "UMAP plots not found. Please run the pipeline first."
}
```

# Conclusion

This modular pipeline provides a robust and extensible framework for benchmarking single-cell integration methods. The results allow for a data-driven decision on the most suitable method for the uTILity atlas, balancing the trade-offs between batch effect removal and conservation of biological identity.

# Session Info

This section provides the session information from the R environment where the document was rendered.

```{r session-info}
sessionInfo()
```
