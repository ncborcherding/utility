---
title: "Processing Combined Data: 200996"
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
output: rmarkdown::html_vignette
theme: united
df_print: kable
vignette: >
  %\VignetteIndexEntry{Processing Combined Data: 200996}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Loading Libraries

```{r}
suppressPackageStartupMessages(library(Seurat))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(viridis))
suppressPackageStartupMessages(library(scDblFinder))
suppressPackageStartupMessages(library(BiocParallel))
suppressPackageStartupMessages(library(RColorBrewer))
suppressPackageStartupMessages(library(SingleR))
suppressPackageStartupMessages(library(celldex))
suppressPackageStartupMessages(library(scRepertoire))
suppressPackageStartupMessages(library(Azimuth))
suppressPackageStartupMessages(library(SeuratData))
suppressPackageStartupMessages(library(scran))
suppressPackageStartupMessages(library(patchwork))
```

# Individual Sequencing Run Processing

```{r eval=FALSE, tidy=FALSE}
dir.create("./qc")

file_list <- list.files("./data/")

###########################
#Load Annotation Reference
###########################
HPCA <- HumanPrimaryCellAtlasData()
Monaco <- MonacoImmuneData()

options(Seurat.object.assay.version = "v5")

for (i in seq_along(file_list)){
    mtx <- list.files(paste0("./data/", file_list[i]), pattern = "h5")
    tmp <-  Read10X_h5(paste0("./data/", file_list[i], "/", mtx))

    tmp <- CreateSeuratObject(counts = tmp, project = file_list[i])
    tmp$nCount_RNA <- colSums(tmp@assays$RNA@layers$counts)
    tmp$nFeature_RNA <- colSums(tmp@assays$RNA@layers$counts != 0)
    
    tmp <- subset(tmp, subset = nFeature_RNA > 100 & nCount_RNA > 100) #filter out low count/feature cells
    tmp  <- RenameCells(object = tmp , new.names = paste0(file_list[i], "_", rownames(tmp[[]])))

    tmp[["mito.genes"]] <- PercentageFeatureSet(tmp, pattern = "^MT-")
    tmp[["ribo.genes"]] <- PercentageFeatureSet(tmp, pattern = "^RPS|RPL-")
    
    VlnPlot(object = tmp, 
            features = c("nCount_RNA", "nFeature_RNA", "mito.genes", "ribo.genes"), 
            pt.size = 0) + 
      theme(legend.position = "none") + 
      plot_layout(ncol =2)
    ggsave(paste0("~/Documents/GitHub/utility/outputs/qc/", file_list[i], ".pdf"), height = 8, width=8)
    
    
    ###########################
    #Here is the filtering step
    ############################
    standev <- sd(log(tmp$nFeature_RNA))*2.5 #cutting off above standard deviation of 2.5
    mean <- mean(log(tmp$nFeature_RNA))
    cut <- round(exp(standev+mean))
    tmp <- subset(tmp, subset = mito.genes < 10 & nFeature_RNA < cut)
    
    ###########################################
    #Estimate Doublets for Each Sequencing Run
    ############################################
    sce <- as.SingleCellExperiment(tmp)
    sce <- scDblFinder(sce, BPPARAM=MulticoreParam(3))
    doublets <- data.frame(db.class = sce$scDblFinder.class, db.score = sce$scDblFinder.score)
    rownames(doublets) <- rownames(sce@colData)
    tmp <- AddMetaData(tmp, doublets)

    ###########################################
    #Seurat Azimuth Annotation
    ############################################
    tmp <- NormalizeData(tmp, verbose = FALSE)
    tmp <- ScaleData(tmp, verbose = FALSE)
    VariableFeatures(tmp) <- getTopHVGs(as.SingleCellExperiment(tmp), 
                                            n=2000)
    tmp <- RunPCA(tmp, verbose = FALSE)
    tmp<- RunUMAP(tmp, dims = 1:30, verbose = FALSE)
    tmp <- FindNeighbors(object = tmp, 
                             features = VariableFeatures(tmp), 
                             verbose = FALSE)
       
    tmp <- RunAzimuth(tmp, 
                          reference = "pbmcref",
                          verbose = FALSE)
       
    #############################################
    #Singler Annotation of Cell Types
    #############################################
      
    com.res1 <- SingleR(sce, ref=HPCA, labels=HPCA$label.fine, assay.type.test=1)
  
    df <- data.frame("labels" = com.res1$labels, "pruned.labels" = com.res1$pruned.labels)
    rownames(df) <- rownames(com.res1)
    colnames(df) <- paste0("HPCA.", colnames(df))
    tmp <- AddMetaData(tmp,  df)
  
    
    com.res2 <- SingleR(sce, ref=Monaco, labels=Monaco$label.fine, assay.type.test=1)
    df <- data.frame("labels" = com.res2$labels, "pruned.labels" = com.res2$pruned.labels)
    rownames(df) <- rownames(com.res1)
    colnames(df) <- paste0("Monaco.", colnames(df))
    tmp <- AddMetaData(tmp,  df)
    rm(df)
    rm(sce)
      
    ######################################
    #Adding TCR clonotypes
    ######################################
    
    TCR.file <- read.csv(paste0("./data/", file_list[i], "/filtered_contig_annotations.csv.gz"))
    combinedObject <- combineTCR(TCR.file, 
                                 samples = file_list[i], 
                                 filterMulti = TRUE)
    tmp <- combineExpression(combinedObject, tmp, cloneCall = "aa")
    
    tmp <- DietSeurat(tmp)
    tmp[["prediction.score.celltype.l1"]] <- NULL
    tmp[["prediction.score.celltype.l2"]] <- NULL
    tmp[["prediction.score.celltype.l3"]] <- NULL
    tmp[["query_ref.nn"]] <- NULL
    tmp@assays$RNA$scale.data <- NULL
    
    #################################
    #Saving Preliminary Seurat Object
    #################################
    saveRDS(tmp, paste0("~/Documents/GitHub/utility/data/processedData/seuratObjects/processedData/", file_list[i], ".rds"))
    rm(tmp)
    gc()
    
}
```

# Mutiplexed Sequencing Run Processing

```{r eval=FALSE, tidy=FALSE}
file_list <- list.files("./multiplexed_data", pattern = ".h5")
exceptions <- file_list[(length(file_list)-3):length(file_list)]
TCR_list <- list.files("./multiplexed_data", pattern = ".csv")
hash.directory <- read.csv("hash.directory.csv", check.names = FALSE, row.names = 1)

for (i in seq_along(file_list)){
    tmp <-  Read10X_h5(paste0("./multiplexed_data/", file_list[i]))
    TCR.file <- read.csv(paste0("./multiplexed_data/", TCR_list[i]))

    umis <- tmp[[1]]

    # For generating a hashtag count matrix from FASTQ files, please refer to
    # https://github.com/Hoohm/CITE-seq-Count.  Load in the HTO count matrix
    htos <- tmp[[2]]
    if(file_list[i] %in% exceptions) {
      htos <- htos[-c(5:7),]
    }

    # Select cell barcodes detected by both RNA and HTO In the example datasets we have already
    # filtered the cells for you, but perform this step for clarity.
    joint.bcs <- intersect(colnames(umis), colnames(htos))

    # Subset RNA and HTO counts by joint cell barcodes
    umis <- umis[, joint.bcs]
    htos <- as.matrix(htos[, joint.bcs])

    pbmc.hashtag <- CreateSeuratObject(counts = umis)
    pbmc.hashtag$nCount_RNA <- colSums(pbmc.hashtag@assays$RNA@layers$counts)
    pbmc.hashtag$nFeature_RNA <- colSums(pbmc.hashtag@assays$RNA@layers$counts != 0)
    
    
    # Normalize RNA data with log normalization
    pbmc.hashtag <- NormalizeData(pbmc.hashtag)
    # Find and scale variable features
    pbmc.hashtag <- FindVariableFeatures(pbmc.hashtag, selection.method = "mean.var.plot")
    pbmc.hashtag <- ScaleData(pbmc.hashtag, features = VariableFeatures(pbmc.hashtag))
    
    # Add HTO data as a new assay independent from RNA
    pbmc.hashtag[["HTO"]] <- CreateAssayObject(counts = htos)
    pbmc.hashtag$nCount_HTO <- colSums(pbmc.hashtag@assays$HTO@counts)
    
    pbmc.hashtag <- subset(pbmc.hashtag, subset = nCount_RNA > 100)
    pbmc.hashtag <- subset(pbmc.hashtag, subset = nCount_HTO > 5)
    # Normalize HTO data, here we use centered log-ratio (CLR) transformation
    pbmc.hashtag <- NormalizeData(pbmc.hashtag, assay = "HTO", normalization.method = "CLR")
    
    pbmc.hashtag <- HTODemux(pbmc.hashtag, assay = "HTO", positive.quantile = 0.99)
    pbmc.hashtag <- subset(pbmc.hashtag, hash.ID != "Doublet")
    
    ####################################
    #This is assigning the sample by HTO
    ####################################
    hash.reference <- hash.directory[,file_list[i]]
    names(hash.reference) <- paste0(paste0("Hashtag", 1:7), "-TotalSeqC")
    pbmc.hashtag$orig.ident <- as.vector(hash.reference[pbmc.hashtag$hash.ID])
    pbmc.hashtag <- subset(pbmc.hashtag, orig.ident != "")
    
    
    pbmc.hashtag <- SplitObject(pbmc.hashtag, split.by = "orig.ident")
    
    for(j in seq_along(pbmc.hashtag)) {
        tmp <- pbmc.hashtag[[j]]
        tmp@meta.data <- tmp@meta.data[,!grepl("HTO|hash", colnames(tmp@meta.data))]
        tmp[["mito.genes"]] <- PercentageFeatureSet(tmp, pattern = "^MT-")
        tmp[["ribo.genes"]] <- PercentageFeatureSet(tmp, pattern = "^RPS|RPL-")
        tmp <- RenameCells(tmp, new.names = paste0(tmp$orig.ident[i], "_", rownames(tmp[[]])))
    
        VlnPlot(object = tmp, 
                features = c("nCount_RNA", "nFeature_RNA", "mito.genes", "ribo.genes"), 
                pt.size = 0) + 
          theme(legend.position = "none") + 
          plot_layout(ncol =2)
        ggsave(paste0("~/Documents/GitHub/utility/outputs/qc/", tmp$orig.ident[1], ".pdf"), height = 8, width=8)
        
        ###########################
        #Here is the filtering step
        ############################
        standev <- sd(log(tmp$nFeature_RNA))*2.5 #cutting off above standard deviation of 2.5
        mean <- mean(log(tmp$nFeature_RNA))
        cut <- round(exp(standev+mean))
        tmp <- subset(tmp, subset = mito.genes < 10 & nFeature_RNA < cut)
        
        ###########################################
        #Estimate Doublets for Each Sequencing Run
        ############################################
        sce <- as.SingleCellExperiment(tmp)
        sce <- scDblFinder(sce, BPPARAM=MulticoreParam(3))
        doublets <- data.frame(db.class = sce$scDblFinder.class, db.score = sce$scDblFinder.score)
        rownames(doublets) <- rownames(sce@colData)
        tmp <- AddMetaData(tmp, doublets)
        
    ###########################################
    #Seurat Azimuth Annotation
    ############################################
        tmp <- NormalizeData(tmp, verbose = FALSE)
        tmp <- ScaleData(tmp, verbose = FALSE)
        VariableFeatures(tmp) <- getTopHVGs(as.SingleCellExperiment(tmp), 
                                            n=2000)
        tmp <- RunPCA(tmp, verbose = FALSE)
        tmp<- RunUMAP(tmp, dims = 1:30, verbose = FALSE)
        tmp <- FindNeighbors(object = tmp, 
                             features = VariableFeatures(tmp), 
                             verbose = FALSE)
       
       tmp <- RunAzimuth(tmp, 
                          reference = "pbmcref",
                          verbose = FALSE)
        #############################################
        #Singler Annotation of Cell Types
        #############################################
         
      com.res1 <- SingleR(sce, ref=HPCA, labels=HPCA$label.fine, assay.type.test=1)
    
      df <- data.frame("labels" = com.res1$labels, "pruned.labels" = com.res1$pruned.labels)
      rownames(df) <- rownames(com.res1)
      colnames(df) <- paste0("HPCA.", colnames(df))
      tmp <- AddMetaData(tmp,  df)
    
      
      com.res2 <- SingleR(sce, ref=Monaco, labels=Monaco$label.fine, assay.type.test=1)
      df <- data.frame("labels" = com.res2$labels, "pruned.labels" = com.res2$pruned.labels)
      rownames(df) <- rownames(com.res1)
      colnames(df) <- paste0("Monaco.", colnames(df))
      tmp <- AddMetaData(tmp,  df)
      rm(df)
      rm(sce)
          
      ######################################
      #Adding TCR clonotypes
      ######################################
        
        combinedObject <- combineTCR(TCR.file, 
                                     samples = tmp$orig.ident[1], 
                                     filterMulti = TRUE)
        tmp <- combineExpression(combinedObject, tmp, cloneCall = "aa")
    
      #################################
      #Saving Preliminary Seurat Object
      #################################
      saveRDS(tmp, paste0("~/Documents/GitHub/utility/data/processedData/seuratObjects/", tmp$orig.ident[1], ".rds"))
    
    }
}
```

